<div >
  <h1 class="text-center mb-3">Proyectos</h1>
  <div class="container-fluid mb-5">
    <div class="container rounded container-fluid  d-block m-auto mb-5">
      <h2 class="text-center ">Lenguaje de programación</h2>
      <div class="carousel card mt-2">
        @for (slide of slides1; track $index) {
          
          @if ($index==currentSlide1) {
            <img
              @carouselAnimation
              [src]="slide.src"
              class="slide"
            />
          }
        }
        <a href="https://github.com/JesusNoel69/LadonLang" target="_blank" class="bottom-image">
          <img class="rounded-circle border-svg" src="../../../assets/images/github-yellow.svg" alt="Github" width="35" height="35">
        </a>
        <button class="control prev" (click)="prevSlide(1)">
          <span class="arrow left"></span>
        </button>
        <button class="control next" (click)="nextSlide(1)">
          <span class="arrow right"></span>
        </button>
      </div>
      <div class="bottom-0 px-5 mx-auto pt-1 mt-3">
        <app-pill name="CSharp" ></app-pill>
      </div>
    </div>
    <p class="bottom-0 text-center m-auto  px-5 mx-auto pt-4 w-100 ">
      Para el lenguaje, se diseñó un autómata finito determinista (AFD) que considera las palabras reservadas que tendrá. Posteriormente, con el autómata, se creó una matriz de transición para manejar cada caso en el analizador léxico.
      Del analizador léxico, se genera un vector de tokens en el que se guarda el tipo de token, el número de línea en donde se encuentra el token y el valor del token en sí. El analizador sintáctico utiliza gramáticas de libre contexto sin recursividad a la izquierda, que manejan los tokens del vector revisando la sintaxis.
      En una clase aparte, se construyó un Árbol de Sintaxis Abstracta (AST) que representa la estructura de cada instrucción y además agrega información a una tabla de símbolos para registrar las funciones, los parámetros, qué variables se declaran y en qué contextos. A partir del AST, se diseñó un Analizador Semántico que, junto con la tabla de símbolos, identifica los contextos de las variables para verificar si su uso es correcto.
      Por último, se creó un generador de código que transforma las instrucciones a un código intermedio de bajo nivel (C++), para posteriormente convertirlo a binario.
    </p>
  </div>

  <div>
  <div class="container-fluid mt-5">
    <div class="container rounded container-fluid  d-block m-auto mb-5">
      <h2 class="text-center ">Red Neuronal</h2>
      <div class="carousel card mt-2">
        @for (slide of slides2; track $index) {
          
          @if ($index==currentSlide2) {
            <img
              @carouselAnimation
              [src]="slide.src"
              class="slide"
            />
          }
        }
        <a href="https://github.com/JesusNoel69/Neural-Network" target="_blank" class="bottom-image">
          <img class="rounded-circle border-svg" src="../../../assets/images/github-yellow.svg" alt="Github" width="35" height="35">
        </a>
        <button class="control prev" (click)="prevSlide(2)">
          <span class="arrow left"></span>
        </button>
        <button class="control next" (click)="nextSlide(2)">
          <span class="arrow right"></span>
        </button>
      </div>
      <div class="bottom-0 px-5 mx-auto pt-1 mt-3">
        <app-pill name="CSharp" ></app-pill>
      </div>
    </div>
    <p class="bottom-0 text-center m-auto  px-5 mx-auto pt-4 w-100 ">
      Para la red neuronal, se creó una clase base que contiene la información de un perceptrón: las entradas de información, el porcentaje de aprendizaje, el sesgo, la salida esperada del perceptrón, el error, y el peso de cada entrada para equilibrarla. Además, se incluyó un método que nos da la suma ponderada de las entradas con los pesos y una función que determina la salida según la suma ponderada.
      Se consideró que la red sería multicapa. Para ello, se utilizó otra clase que contiene una capa de entrada (que son solo las entradas de la evaluación), un número determinado de capas ocultas, donde cada capa tiene un cierto número de perceptrones. El número de entradas de cada perceptrón es igual al número de salidas de la capa anterior, por lo que cada entrada es la salida de cada perceptrón de la capa anterior. Finalmente, hay una capa de salida que contiene un número de perceptrones y es en esta capa donde se realiza el entrenamiento.
      El entrenamiento consiste en ajustar los errores utilizando los pesos de cada dato de entrada y retropropagándolos hacia atrás (desde la última capa se calculan los errores de cada salida de cada perceptrón y se ajustan sus pesos).
    </p>
  </div>